{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, Alpha=0.01, Epochs=100):\n",
    "        self.X = np.nan  # Input Features\n",
    "        self.Y = np.nan  # Input Labels\n",
    "        self.Thetas = np.nan\n",
    "        self.Alpha = Alpha  # Learning Rate\n",
    "        self.Epochs = Epochs  # Total Number of Iterations\n",
    "        self.Losses = np.array([])\n",
    "    \n",
    "    def Fit(self, X, Y, PrintLoss=False):\n",
    "        # Converting X and Y into NumPy Arrays\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        self.X = np.c_[X, np.ones(len(Y))]  # Appending a Column of 1s for Vectorized Operations\n",
    "        self.Y = np.asarray(Y, dtype=np.float32)\n",
    "\n",
    "        Thetas = np.random.rand(self.X.shape[1])  # Range: 0 to 1\n",
    "        # Thetas = np.random.uniform(-1, 1, self.X.shape[1])  # Range: -1 to 1\n",
    "        for Epoch in range(1, self.Epochs+1):\n",
    "            Predicted = np.dot(self.X, Thetas)  # Hypothesis\n",
    "            Loss = np.mean((self.Y-Predicted)**2)  # Loss Function: Mean Squared Error\n",
    "            Derivative = (np.dot((self.Y-Predicted), self.X)*-2)/len(self.Y)  # Derivative of Loss Function\n",
    "            Thetas -= self.Alpha * Derivative  # Gradient Descent\n",
    "            if PrintLoss:\n",
    "                print(f\"Epoch: {Epoch}, Loss: {Loss}\")\n",
    "            self.Losses = np.append(self.Losses, Loss)\n",
    "        self.Thetas = Thetas\n",
    "        return self.Thetas, self.Losses[-1]\n",
    "\n",
    "    def Predict(self, X):\n",
    "        # Converting X into a NumPy Array\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        if X.ndim == 1:  # Prediction for Single Value\n",
    "            X = np.r_[X, np.ones(1)]  # Appending a 1 for Vectorized Operation\n",
    "        else:  # Prediction for Multiple Values\n",
    "            X = np.c_[X, np.ones(len(X))]  # Appending a Column of 1s for Vectorized Operation\n",
    "        return np.dot(self.Thetas, X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Final Loss is: 0.005729550312347864\n"
     ]
    }
   ],
   "source": [
    "DataFrame = pd.read_csv(\"Advertising.csv\", index_col=\"Unnamed: 0\")\n",
    "# Converting the Training Dataset into NumPy Arrays and Scaling Between the Range 0 to 1\n",
    "X = np.asarray(DataFrame[[\"TV\", \"radio\", \"newspaper\"]])\n",
    "X = (X - (np.min(X, axis=0))) / np.ptp(X, axis=0)\n",
    "Y = np.asarray(DataFrame[\"sales\"])\n",
    "Y = (Y - np.min(Y)) / np.ptp(Y)\n",
    "\n",
    "Model = LinearRegression(Alpha=0.02, Epochs=1000)\n",
    "Thetas, Loss = Model.Fit(X[:150, :], Y[:150])  # Taking the First 150 Examples as Train Dataset\n",
    "Prediction = Model.Predict(X[150:, :])\n",
    "Actual = Y[150:]\n",
    "print(f\"The Final Loss is: {Loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
